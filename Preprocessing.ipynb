{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to specify all the required packages to be able to use BERT and Tensorflow. We use numpy and pandas to load and change our data so that it can be handled by the BERT Tensorflow module. Furthermore, we drop all of the additional columns since we only really need the \"comment_text\" and \"target\" column to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import run_classifier\n",
    "import tokenization\n",
    "import modeling\n",
    "import optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "# device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Is this something I'll be able to install on m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59856</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    target                                       comment_text\n",
       "0  59848  0.000000  This is so cool. It's like, 'would you want yo...\n",
       "1  59849  0.000000  Thank you!! This would make my life a lot less...\n",
       "2  59852  0.000000  This is such an urgent design problem; kudos t...\n",
       "3  59855  0.000000  Is this something I'll be able to install on m...\n",
       "4  59856  0.893617               haha you guys are a bunch of losers."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "data = data.drop(['severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat', 'asian', 'atheist', 'bisexual',\n",
    "                  'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu', 'homosexual_gay_or_lesbian',\n",
    "                  'intellectual_or_learning_disability', 'jewish', 'latino', 'male', 'muslim', 'other_disability', \n",
    "                  'other_gender', 'other_race_or_ethnicity', 'other_religion', 'other_sexual_orientation', \n",
    "                  'physical_disability', 'psychiatric_or_mental_illness', 'transgender', 'white', 'created_date', \n",
    "                  'publication_id', 'parent_id', 'article_id', 'rating', 'funny', 'wow', 'sad', 'likes', 'disagree', \n",
    "                  'sexual_explicit', 'identity_annotator_count', 'toxicity_annotator_count'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean value for the target column:   0.1028532806939755\n",
      "Number of targets higher than 0.5:  53073\n",
      "Number of targets higher than 0.0:  269530\n",
      "Number of comments:                 902437\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean value for the target column:  \", data[\"target\"].mean())\n",
    "print(\"Number of targets higher than 0.5: \", data[(data['target'] >0.5)][\"target\"].count())\n",
    "print(\"Number of targets higher than 0.0: \", data[(data['target'] >0.0)][\"target\"].count())\n",
    "print(\"Number of comments:                \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of targets higher than 0.0:  269530\n"
     ]
    }
   ],
   "source": [
    "data['label'] = np.where(data['target']>0,1,0)\n",
    "label_list = list(data['label'].unique())\n",
    "label_list\n",
    "print(\"Number of targets higher than 0.0: \", data[(data['target'] >0.0)][\"target\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a fraction of the sample fraction. Essentially we should always keep this between 0.7-0.9\n",
    "training_frac = 0.8\n",
    "train_len = int(len(data)*training_frac)\n",
    "valid_len = int(len(data)*(1.0-training_frac))\n",
    "\n",
    "train = data.iloc[:train_len, :]\n",
    "valid = data.iloc[:valid_len, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.5/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/jupyter/.local/lib/python3.5/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train0 = train[train[\"label\"]==0]\n",
    "train1 = train[train[\"label\"]==1]\n",
    "train0[\"count\"] = train0['comment_text'].str.split().str.len()\n",
    "train1[\"count\"] = train1['comment_text'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "x = pd.Series(train0[\"count\"])\n",
    "ax = sns.distplot(x, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "x = pd.Series(train1[\"count\"])\n",
    "ax = sns.distplot(x, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BERT_CONFIG_FILE = \"./bert/bert_config.json\"\n",
    "INIT_CHECKPOINT = './bert/bert-model.ckpt'\n",
    "VOCAB_FILE = \"./bert/vocab.txt\"\n",
    "OUTPUT_DIR = './output4'\n",
    "TRAIN_FILE = \"./output4/train.tf_record\"\n",
    "VALID_FILE = \"./output4/valid.tf_record\"\n",
    "DO_LOWER_CASE = False\n",
    "DO_TRAIN = True\n",
    "DO_EVAL = False\n",
    "DO_PREDICT = False\n",
    "USE_TPU = False\n",
    "USE_ONE_HOT_EMBEDDING = False\n",
    "MAX_SEQ_LENGTH = 512\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "EVAL_BATCH_SIZE = 32\n",
    "PREDICT_BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5 \n",
    "NUM_TRAIN_EPOCHS = 1.0\n",
    "WARMUP_PROPORTION = 0.1\n",
    "MASTER = None\n",
    "SAVE_CHECKPOINTS_STEPS = 5000\n",
    "ITERATIONS_PER_LOOP = 1000\n",
    "NUM_TPU_CORES = 1\n",
    "TPU_CLUSTER_RESOLVER = None\n",
    "IS_PER_HOST = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case=DO_LOWER_CASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_input(x):\n",
    "    return run_classifier.InputExample(guid=x[\"id\"], \n",
    "                                       text_a = x[\"comment_text\"],\n",
    "                                       text_b = None, \n",
    "                                       label = x[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_InputExamples = train.apply(convert_input, axis= 1)\n",
    "valid_InputExamples = valid.apply(convert_input, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Writing example 0 of 18048\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: 59848\n",
      "INFO:tensorflow:tokens: [CLS] This is so cool . It ' s like , ' would you want your mother to read this ? ? ' Really great idea , well done ! [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1188 1110 1177 4348 119 1135 112 188 1176 117 112 1156 1128 1328 1240 1534 1106 2373 1142 136 136 112 8762 1632 1911 117 1218 1694 106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: 59849\n",
      "INFO:tensorflow:tokens: [CLS] Thank you ! ! This would make my life a lot less anxiety - in ##ducing . Keep it up , and don ' t let anyone get in your way ! [SEP]\n",
      "INFO:tensorflow:input_ids: 101 4514 1128 106 106 1188 1156 1294 1139 1297 170 1974 1750 10507 118 1107 17484 119 7947 1122 1146 117 1105 1274 112 189 1519 2256 1243 1107 1240 1236 106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: 59852\n",
      "INFO:tensorflow:tokens: [CLS] This is such an urgent design problem ; k ##udo ##s to you for taking it on . Very impressive ! [SEP]\n",
      "INFO:tensorflow:input_ids: 101 1188 1110 1216 1126 14844 1902 2463 132 180 18109 1116 1106 1128 1111 1781 1122 1113 119 6424 7757 106 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: 59855\n",
      "INFO:tensorflow:tokens: [CLS] Is this something I ' ll be able to install on my site ? When will you be releasing it ? [SEP]\n",
      "INFO:tensorflow:input_ids: 101 2181 1142 1380 146 112 1325 1129 1682 1106 17812 1113 1139 1751 136 1332 1209 1128 1129 8210 1122 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 0 (id = 0)\n",
      "INFO:tensorflow:*** Example ***\n",
      "INFO:tensorflow:guid: 59856\n",
      "INFO:tensorflow:tokens: [CLS] ha ##ha you guys are a bunch of loser ##s . [SEP]\n",
      "INFO:tensorflow:input_ids: 101 5871 2328 1128 3713 1132 170 9670 1104 19398 1116 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "INFO:tensorflow:label: 1 (id = 1)\n",
      "INFO:tensorflow:Writing example 10000 of 18048\n"
     ]
    }
   ],
   "source": [
    "run_classifier.file_based_convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer, TRAIN_FILE)\n",
    "run_classifier.file_based_convert_examples_to_features(valid_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer, VALID_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN_STEPS = int(len(train_InputExamples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "NUM_WARMUP_STEPS = int(NUM_TRAIN_STEPS * WARMUP_PROPORTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_config = modeling.BertConfig.from_json_file(BERT_CONFIG_FILE)\n",
    "\n",
    "tpu_config = tf.contrib.tpu.TPUConfig(\n",
    "    iterations_per_loop=ITERATIONS_PER_LOOP,\n",
    "    num_shards=NUM_TPU_CORES,\n",
    "    per_host_input_for_training=IS_PER_HOST)\n",
    "\n",
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "    cluster=TPU_CLUSTER_RESOLVER,\n",
    "    master=MASTER,\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
    "    tpu_config=tpu_config)\n",
    "\n",
    "model_fn = run_classifier.model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    num_labels=len(label_list),\n",
    "    init_checkpoint=INIT_CHECKPOINT,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_steps=NUM_TRAIN_STEPS,\n",
    "    num_warmup_steps=NUM_WARMUP_STEPS,\n",
    "    use_tpu=USE_TPU,\n",
    "    use_one_hot_embeddings=USE_ONE_HOT_EMBEDDING)\n",
    "\n",
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "    use_tpu=USE_TPU,\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    eval_batch_size=EVAL_BATCH_SIZE,\n",
    "    predict_batch_size=PREDICT_BATCH_SIZE)  \n",
    "\n",
    "train_input_fn = run_classifier.file_based_input_fn_builder(\n",
    "    input_file=TRAIN_FILE,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.train(input_fn=train_input_fn, max_steps=NUM_TRAIN_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_input_fn = run_classifier.file_based_input_fn_builder(\n",
    "    input_file=VALID_FILE, \n",
    "    seq_length=MAX_SEQ_LENGTH, \n",
    "    is_training=False, \n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f6fcee8f9d8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_num_ps_replicas': 0, '_log_step_count_steps': None, '_num_worker_replicas': 1, '_model_dir': './output2/', '_protocol': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_global_id_in_cluster': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6fc6adc198>, '_tf_random_seed': None, '_evaluation_master': '', '_cluster': None, '_eval_distribute': None, '_task_id': 0, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': 5000, '_service': None, '_experimental_distribute': None, '_is_chief': True, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=1, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_task_type': 'worker', '_device_fn': None, '_train_distribute': None, '_master': '', '_keep_checkpoint_max': 5}\n",
      "WARNING:tensorflow:Setting TPUConfig.num_shards==1 is an unsupported behavior. Please fix as soon as possible (leaving num_shards as None.)\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
      "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n"
     ]
    }
   ],
   "source": [
    "bert_config = modeling.BertConfig.from_json_file(BERT_CONFIG_FILE)\n",
    "\n",
    "INIT_CHECKPOINT = './output2/model.ckpt-45121'\n",
    "\n",
    "tpu_config = tf.contrib.tpu.TPUConfig(\n",
    "    iterations_per_loop=ITERATIONS_PER_LOOP,\n",
    "    num_shards=NUM_TPU_CORES,\n",
    "    per_host_input_for_training=IS_PER_HOST)\n",
    "\n",
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "    cluster=TPU_CLUSTER_RESOLVER,\n",
    "    master=MASTER,\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
    "    tpu_config=tpu_config)\n",
    "\n",
    "model_fn = run_classifier.model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    num_labels=len(label_list),\n",
    "    init_checkpoint=INIT_CHECKPOINT,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_steps=NUM_TRAIN_STEPS,\n",
    "    num_warmup_steps=NUM_WARMUP_STEPS,\n",
    "    use_tpu=USE_TPU,\n",
    "    use_one_hot_embeddings=USE_ONE_HOT_EMBEDDING)\n",
    "\n",
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "    use_tpu=USE_TPU,\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    eval_batch_size=EVAL_BATCH_SIZE,\n",
    "    predict_batch_size=PREDICT_BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/jupyter/run_classifier.py:547: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "WARNING:tensorflow:From /home/jupyter/run_classifier.py:527: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Running eval on CPU\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (?, 512)\n",
      "INFO:tensorflow:  name = input_mask, shape = (?, 512)\n",
      "INFO:tensorflow:  name = is_real_example, shape = (?,)\n",
      "INFO:tensorflow:  name = label_ids, shape = (?,)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (?, 512)\n",
      "WARNING:tensorflow:From /home/jupyter/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/jupyter/run_classifier.py:612: Print (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2018-08-20.\n",
      "Instructions for updating:\n",
      "Use tf.print instead of tf.Print. Note that tf.print returns a no-output operator that directly prints the output. Outside of defuns or eager mode, this operator will not be executed unless it is directly specified in session.run or used as a control dependency for other operators. This is only a concern in graph mode. Below is an example of how to ensure tf.print executes in graph mode:\n",
      "```python\n",
      "    sess = tf.Session()\n",
      "    with sess.as_default():\n",
      "        tensor = tf.range(10)\n",
      "        print_op = tf.print(tensor)\n",
      "        with tf.control_dependencies([print_op]):\n",
      "          out = tf.add(tensor, tensor)\n",
      "        sess.run(out)\n",
      "    ```\n",
      "Additionally, to use tf.print in python 2.7, users must make sure to import\n",
      "the following:\n",
      "\n",
      "  `from __future__ import print_function`\n",
      "\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (28996, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/ops/metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-16T20:38:53Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./output2/model.ckpt-45121\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-16-20:46:25\n",
      "INFO:tensorflow:Saving dict for global step 45121: eval_accuracy = 0.97606385, eval_loss = 0.08503706, global_step = 45121, loss = 0.08503706\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 45121: ./output2/model.ckpt-45121\n",
      "INFO:tensorflow:evaluation_loop marked as finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.97606385,\n",
       " 'eval_loss': 0.08503706,\n",
       " 'global_step': 45121,\n",
       " 'loss': 0.08503706}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.evaluate(input_fn=valid_input_fn, steps=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
